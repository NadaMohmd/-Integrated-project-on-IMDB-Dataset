# -*- coding: utf-8 -*-
"""Copy of Yet another copy of IMDB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DG2Gj5VWizhlvW5FIy4kPKWGcIMNxCKy
"""

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.js

!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews

!unzip /content/imdb-dataset-of-50k-movie-reviews.zip

import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score ,confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding, SpatialDropout1D
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D
import matplotlib.pyplot as plt

data=pd.read_csv('IMDB Dataset.csv')

data.head(20)

"""**Data Analysis**"""

data.shape

data.isnull().sum()

data.sentiment.value_counts()

data.review.value_counts()

data.duplicated().sum()

"""**Data cleaning**"""

data = data.drop_duplicates()

data['review'].value_counts().nlargest(10).plot(kind='bar')
plt.title('Top 10 review')
plt.xlabel('review')
plt.ylabel('Count')
plt.show()

sentiment_count = data.sentiment.value_counts().nlargest(5)
plt.figure(figsize=(8, 6))
plt.pie(sentiment_count.values, labels=sentiment_count.index, autopct='%1.1f%%', startangle=90)
plt.title('Top sentiment')
plt.show()

"""**Encoding**"""

data['sentiment'] = data['sentiment'].map({'negative': 0, 'positive': 1})

"""**Text Cleaning**"""

def clean_text(text):
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = text.lower()
    return text

data['review'] = data['review'].apply(clean_text)

"""**Text Vectorization**"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(data['review']).toarray()
y = data['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""**SVM model**"""

svm_model = SVC(kernel='linear')
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)

print('SVM Model Accuracy:', accuracy_score(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm))

"""**Logistic Regression**"""

ml_model = LogisticRegression()
ml_model.fit(X_train, y_train)

y_pred_ml = ml_model.predict(X_test)
print('ML Model Accuracy:', accuracy_score(y_test, y_pred_ml))
print(classification_report(y_test, y_pred_ml))

"""**confusion matrix shows the true vs. predicted classes for the modelâ€™s predictions**"""

conf_matrix = confusion_matrix(y_test, y_pred_svm)

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.title('Confusion Matrix - SVM')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""**Accuracy Comparison of ML Models (SVM vs Logistic Regression)**"""

accuracies = [accuracy_score(y_test, y_pred_ml), accuracy_score(y_test, y_pred_svm)]
model_names = ['Logistic Regression', 'SVM']

plt.figure(figsize=(8, 6))
plt.bar(model_names, accuracies, color=['lightblue', 'lightgreen'])
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

"""**Deep Learning ( CNN )**"""

X = data['review']
y = data['sentiment']

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

max_words = 5000
max_len = 150
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

model = Sequential()
model.add(Embedding(max_words, 128, input_length=max_len))
model.add(SpatialDropout1D(0.2))
model.add(LSTM(100))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten

model_cnn = Sequential()
model_cnn.add(Embedding(max_words, 128, input_length=max_len))
model_cnn.add(Conv1D(filters=64, kernel_size=5, activation='relu'))
model_cnn.add(MaxPooling1D(pool_size=2))
model_cnn.add(Flatten())
model_cnn.add(Dense(10, activation='relu'))
model_cnn.add(Dense(1, activation='sigmoid'))

model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history_cnn = model_cnn.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))

"""**RNN**"""

history = model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))

loss, accuracy = model.evaluate(X_test_pad, y_test)
print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend()
plt.show()

print(X_train.shape)
print(X_test.shape)

max_len = 150

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Embedding

model_nn = Sequential()
model_nn.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))
model_nn.add(Flatten())
model_nn.add(Dense(10, activation='relu'))
model_nn.add(Dropout(0.5))
model_nn.add(Dense(1, activation='sigmoid'))

model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])


history_nn = model_nn.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))

loss_nn, accuracy_nn = model_nn.evaluate(X_test_pad, y_test)
print(f'Loss (NN): {loss_nn:.4f}, Accuracy (NN): {accuracy_nn:.4f}')

import matplotlib.pyplot as plt

plt.plot(history_nn.history['accuracy'], label='Training Accuracy')
plt.plot(history_nn.history['val_accuracy'], label='Validation Accuracy')
plt.title('Neural Network Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

plt.plot(history_nn.history['loss'], label='Training Loss')
plt.plot(history_nn.history['val_loss'], label='Validation Loss')
plt.title('Neural Network Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

"""**Connecting Deep Learning with Machine Learning**"""

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

feature_extractor = Model(inputs=model_nn.input, outputs=model_nn.layers[-2].output)

deep_features_train = feature_extractor.predict(X_train_pad)
deep_features_test = feature_extractor.predict(X_test_pad)
print(deep_features_train.shape)
print(deep_features_test.shape)

from tensorflow.keras.models import Model
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

feature_extractor = Model(inputs=model_nn.input, outputs=model_nn.layers[-2].output)
deep_features_train = feature_extractor.predict(X_train_pad)
deep_features_test = feature_extractor.predict(X_test_pad)

ml_model = RandomForestClassifier(n_estimators=100)
ml_model.fit(deep_features_train, y_train)

y_pred = ml_model.predict(deep_features_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy of the ML model: {accuracy:.4f}')

"""**Train ML Model on Deep Features**"""

hybrid_model = LogisticRegression()
hybrid_model.fit(deep_features_train, y_train)

y_pred_hybrid = hybrid_model.predict(deep_features_test)
print('Hybrid Model Accuracy:', accuracy_score(y_test, y_pred_hybrid))
print(classification_report(y_test, y_pred_hybrid))